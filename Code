"""
@author: NIKA
"""
"""

import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from keras import layers
import skimage.transform as skTrans
from skimage.util import crop
import nibabel as nib
from scipy import ndimage
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from keras.layers import Conv3D, MaxPooling3D
from keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, AveragePooling3D, BatchNormalization, Flatten
from keras.initializers import glorot_uniform
from sklearn.metrics import recall_score
from keras.models import load_model
from matplotlib.ticker import PercentFormatter
import glob
from tensorflow.keras.utils import to_categorical



#Define dataloader

def load_img(img_dir, img_list):
    images=[]
    for i, image_name in enumerate(img_list):    
        if (image_name.split('.')[1] == 'npy'):
            
            image = np.load(img_dir+image_name)
                      
            images.append(image)
    images = np.array(images)
    
    return(images)
  

def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):

    L = len(img_list)

    #keras needs the generator infinite, so we will use while true  
    while True:

        batch_start = 0
        batch_end = batch_size

        while batch_start < L:
            limit = min(batch_end, L)
                       
            X = load_img(img_dir, img_list[batch_start:limit])
            Y = load_img(mask_dir, mask_list[batch_start:limit])

            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     

            batch_start += batch_size   
            batch_end += batch_size


#Define the image generators for training and validation

train_img_dir = '...'
train_mask_dir = '...'

val_img_dir = '...'
val_mask_dir = '...'


train_img_list= os.listdir(train_img_dir)
train_mask_list = os.listdir(train_mask_dir)

val_img_list= os.listdir(val_img_dir)
val_mask_list = os.listdir(val_mask_dir)

batch_size = 1
 
train_img_datagen = imageLoader(train_img_dir, train_img_list, 
                                train_mask_dir, train_mask_list, batch_size)

val_img_datagen = imageLoader(val_img_dir, val_img_list, 
                                val_mask_dir, val_mask_list, batch_size)



#Verify generator.... In python 3 next() is renamed as __next__()
import random

img, msk = train_img_datagen.__next__()

img_num = random.randint(0,img.shape[0]-1)
test_img=img[img_num]
test_mask=msk[img_num]
test_mask=np.argmax(test_mask, axis=3)

n_slice=random.randint(0, test_mask.shape[2])
plt.figure(figsize=(12, 8))

plt.subplot(221)
plt.imshow(test_img[:,:,n_slice, 0], cmap='gray')
plt.title('PET Scan')
plt.subplot(222)
plt.imshow(test_img[:,:,n_slice, 1], cmap='gray')
plt.title('CT Scan')
plt.subplot(224)
plt.imshow(test_mask[:,:,n_slice])
plt.title('Mask')
plt.show()


#############################################################
#Optional step of finding the distribution of each class and calculating appropriate weights
#Alternatively you can just assign equal weights and see how well the model performs: 0.25, 0.25, 0.25, 0.25
'''
import pandas as pd
columns = ['0','1','2','3','4','5','6']
df = pd.DataFrame(columns=columns)
train_mask_list = sorted(glob.glob('...'))
for img in range(len(train_mask_list)):
    #print(img)
    temp_image=np.load(train_mask_list[img])
    temp_image = np.argmax(temp_image, axis=3)
    val, counts = np.unique(temp_image, return_counts=True)
    zipped = zip(columns, counts)
    conts_dict = dict(zipped)
    
    df = df.append(conts_dict, ignore_index=True)

label_0 = df['0'].sum()
label_1 = df['1'].sum()
label_2 = df['2'].sum()
label_3 = df['3'].sum()
label_4 = df['4'].sum()
label_5 = df['5'].sum()
label_6 = df['6'].sum()
total_labels = label_0 + label_1 + label_2 + label_3 + label_4 + label_5 + label_6
n_classes = 7
#Class weights claculation: n_samples / (n_classes * n_samples_for_class)
wt0 = round((total_labels/(n_classes*label_0)), 2) #round to 2 decimals
wt1 = round((total_labels/(n_classes*label_1)), 2)
wt2 = round((total_labels/(n_classes*label_2)), 2)
wt3 = round((total_labels/(n_classes*label_3)), 2)
wt4 = round((total_labels/(n_classes*label_4)), 2)
wt5 = round((total_labels/(n_classes*label_5)), 2)
wt6 = round((total_labels/(n_classes*label_6)), 2)
#Weights are: 0.26, 22.53, 22.53, 26.21
#wt0, wt1, wt2, wt3 = 0.26, 22.53, 22.53, 26.21
#These weihts can be used for Dice loss 

print('Weights are:', wt0,',', wt1,',', wt2,',', wt3,',', wt4,',', wt5,',', wt6)
#2496,312,Weights are: ...     
'''

print(len(train_img_list))
print(len(train_mask_list))

print(len(val_img_list))
print(len(val_mask_list)) 

##############################################################

#Define loss, metrics and optimizer to be used for training
wt0, wt1, wt2, wt3, wt4, wt5, wt6 = ...

import segmentation_models_3D as sm


dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3, wt4, wt5, wt6])) 
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)


metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]

#Define parameters for our model.

encoder_weights= None
BACKBONE = 'vgg16'  #Try vgg16, efficientnetb7, inceptionv3, resnet50
activation = 'softmax'
patch_size = 128
n_classes = 7
channels= 2
  
LR = 0.0001
optim = keras.optimizers.Adam(LR)

###############################################################

#Fit the model 

steps_per_epoch = len(train_img_list)//batch_size
val_steps_per_epoch = len(val_img_list)//batch_size


model = sm.Unet(BACKBONE, classes=n_classes, 
                input_shape=(patch_size, patch_size, patch_size, channels), 
                encoder_weights=encoder_weights,
                activation=activation)

print(model.summary())
print(model.input_shape)
print(model.output_shape)

###############################################################

model.compile(optimizer = optim, loss=total_loss, metrics=metrics)



# Define callbacks.
csv_logger = keras.callbacks.CSVLogger(
    '...',separator=",",append=False)

checkpoint_cb = keras.callbacks.ModelCheckpoint(
    "...", save_best_only=True, verbose=1)

early_stopping_cb = keras.callbacks.EarlyStopping(monitor="val_acc", patience=15, verbose=1)





history=model.fit(train_img_datagen,
          steps_per_epoch=steps_per_epoch,
          epochs=100,
          verbose=1,
          validation_data=val_img_datagen,
          validation_steps=val_steps_per_epoch,
          callbacks=[csv_logger],
          )

# Save the model
model.save('....')
